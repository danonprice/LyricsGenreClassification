{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bert-tensorflow in /Users/DanP/anaconda/lib/python3.6/site-packages (1.0.1)\r\n",
      "Requirement already satisfied: six in /Users/DanP/anaconda/lib/python3.6/site-packages (from bert-tensorflow) (1.10.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install bert-tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/DanP/anaconda/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import bert\n",
    "from bert import run_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Number of Records: 362237\n",
      "Number of deleted records: 117033\n",
      "Number of Records after records deleted: 223560\n",
      "training label shape: (13464,)\n",
      "test label shape: (44712,)\n",
      "dev label shape: (44712,)\n",
      "labels names: Index(['Rock', 'Pop', 'Hip-Hop', 'Metal', 'Country', 'Jazz', 'Electronic',\n",
      "       'Other', 'R&B', 'Indie', 'Folk'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "def is_nan(string_value):\n",
    "    if isinstance(string_value, float):\n",
    "        if math.isnan(string_value):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "lyrics = pd.read_csv('lyrics.csv')\n",
    "print('Original Number of Records:',len(lyrics))\n",
    "\n",
    "# Preprocessed records to remove \n",
    "# a. strings containing less than 10 words\n",
    "# b. non-english records using langdetect package\n",
    "# See Preprocessor.ipynb \n",
    "with open(\"drop_list.txt\") as f:\n",
    "    content = f.readlines()\n",
    "    \n",
    "non_english =[int(x.strip()) for x in content[0].split(',')]\n",
    "\n",
    "# find all records with nan\n",
    "nans = []\n",
    "for i,record in enumerate(lyrics['lyrics']):\n",
    "    if is_nan(record):\n",
    "        nans.append(i)\n",
    "                \n",
    "drop_set = set()\n",
    "for i in non_english: drop_set.add(i)\n",
    "for i in nans: drop_set.add(i)\n",
    "drop_list = list(drop_set)\n",
    "lyrics = lyrics.drop(drop_list,axis=0)\n",
    "lyrics = lyrics.drop(lyrics[lyrics.genre == 'Not Available'].index)\n",
    "\n",
    "print('Number of deleted records:',len(drop_list))\n",
    "print('Number of Records after records deleted:',len(lyrics))\n",
    "\n",
    "lyrics['line_count'] = [lyric.count('\\n')+1 for lyric in lyrics['lyrics']]\n",
    "\n",
    "lyrics_train, lyrics_test = train_test_split(lyrics, test_size=0.4, random_state=5)\n",
    "\n",
    "rock_train = lyrics_train[lyrics_train['genre'] == 'Rock']\n",
    "pop_train = lyrics_train[lyrics_train['genre'] == 'Pop']\n",
    "hiphop_train = lyrics_train[lyrics_train['genre'] == 'Hip-Hop']\n",
    "metal_train = lyrics_train[lyrics_train['genre'] == 'Metal']\n",
    "country_train = lyrics_train[lyrics_train['genre'] == 'Country']\n",
    "jazz_train = lyrics_train[lyrics_train['genre'] == 'Jazz']\n",
    "electronic_train = lyrics_train[lyrics_train['genre'] == 'Electronic']\n",
    "other_train = lyrics_train[lyrics_train['genre'] == 'Other']\n",
    "rnb_train = lyrics_train[lyrics_train['genre'] == 'R&B']\n",
    "indie_train = lyrics_train[lyrics_train['genre'] == 'Indie']\n",
    "folk_train = lyrics_train[lyrics_train['genre'] == 'Folk']\n",
    "\n",
    "# Oversample the success records to balance the skewed classes.\n",
    "# train_data1 = pd.concat([train_df_fail, train_df_success.sample(len(train_df_fail.index),replace=True)], axis = 0)\n",
    "#lyrics_train_oversample = pd.concat([rock_train, \\\n",
    "#                                  pop_train.sample(len(rock_train.index),replace=True), \\\n",
    "#                                  hiphop_train.sample(len(rock_train.index),replace=True), \\\n",
    "#                                  metal_train.sample(len(rock_train.index),replace=True), \\\n",
    "#                                  country_train.sample(len(rock_train.index),replace=True), \\\n",
    "#                                  jazz_train.sample(len(rock_train.index),replace=True), \\\n",
    "#                                  electronic_train.sample(len(rock_train.index),replace=True), \\\n",
    "#                                  other_train.sample(len(rock_train.index),replace=True), \\\n",
    "#                                  rnb_train.sample(len(rock_train.index),replace=True), \\\n",
    "#                                  indie_train.sample(len(rock_train.index),replace=True), \\\n",
    "#                                  folk_train.sample(len(rock_train.index),replace=True)], axis = 0)\n",
    "\n",
    "\n",
    "lyrics_train_undersample = pd.concat([rock_train.sample(len(folk_train.index),replace=False), \\\n",
    "                                  pop_train.sample(len(folk_train.index),replace=False), \\\n",
    "                                  hiphop_train.sample(len(folk_train.index),replace=False), \\\n",
    "                                  metal_train.sample(len(folk_train.index),replace=False), \\\n",
    "                                  country_train.sample(len(folk_train.index),replace=False), \\\n",
    "                                  jazz_train.sample(len(folk_train.index),replace=False), \\\n",
    "                                  electronic_train.sample(len(folk_train.index),replace=False), \\\n",
    "                                  other_train.sample(len(folk_train.index),replace=False), \\\n",
    "                                  rnb_train.sample(len(folk_train.index),replace=False), \\\n",
    "                                  indie_train.sample(len(folk_train.index),replace=False), \\\n",
    "                                  folk_train], axis = 0)\n",
    "\n",
    "genres = lyrics['genre'].value_counts().keys()\n",
    "\n",
    "num_test = len(lyrics_test)\n",
    "test_data, test_labels = lyrics_test.drop(['genre'],axis=1)[int(num_test/2):], lyrics_test['genre'][int(num_test/2):]\n",
    "dev_data, dev_labels = lyrics_test.drop(['genre'],axis=1)[:int(num_test/2)], lyrics_test['genre'][:int(num_test/2)]\n",
    "#train_data, train_labels = lyrics_train.drop(['genre'],axis=1), lyrics_train['genre']\n",
    "#train_data, train_labels = lyrics_train_oversample.drop(['genre'],axis=1), lyrics_train_oversample['genre']\n",
    "train_data, train_labels = lyrics_train_undersample.drop(['genre'],axis=1), lyrics_train_undersample['genre']\n",
    "\n",
    "\n",
    "print ('training label shape:', train_labels.shape)\n",
    "print ('test label shape:', test_labels.shape)\n",
    "print ('dev label shape:', dev_labels.shape)\n",
    "print ('labels names:', genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_InputExamples = train_data.apply(lambda x: bert.run_classifier.InputExample(guid=None, # Globally unique ID for bookkeeping, unused in this example\n",
    "                                                                   text_a = train_data.lyrics, \n",
    "                                                                   text_b = None, \n",
    "                                                                   label = train_labels), axis = 1)\n",
    "\n",
    "test_InputExamples = test_data.apply(lambda x: bert.run_classifier.InputExample(guid=None, \n",
    "                                                                   text_a = test_data.lyrics, \n",
    "                                                                   text_b = None, \n",
    "                                                                   label = test_labels), axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Link to download the BERT model used in next cell\n",
    "https://storage.googleapis.com/bert_models/2018_10_18/uncased_L-12_H-768_A-12.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bert import tokenization\n",
    "\n",
    "BERT_VOCAB= \"uncased_L-12_H-768_A-12/vocab.txt\"\n",
    "BERT_INIT_CHKPNT = \"uncased_L-12_H-768_A-12/bert_model.ckpt\"\n",
    "BERT_CONFIG = \"uncased_L-12_H-768_A-12/bert_config.json\"\n",
    "tokenization.validate_case_matches_checkpoint(True,BERT_INIT_CHKPNT)\n",
    "tokenizer = tokenization.FullTokenizer(vocab_file=BERT_VOCAB, do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30522"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['this',\n",
       " 'is',\n",
       " 'just',\n",
       " 'an',\n",
       " 'ordinary',\n",
       " 'day',\n",
       " 'wipe',\n",
       " 'the',\n",
       " 'ins',\n",
       " '##ec',\n",
       " '##urities',\n",
       " 'away',\n",
       " 'i',\n",
       " 'can',\n",
       " 'see',\n",
       " 'that',\n",
       " 'the',\n",
       " 'dar']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize(train_data.lyrics.values[1][0:78])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
