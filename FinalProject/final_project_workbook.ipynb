{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Classification of Music Lyrics by Genre\n",
    "\n",
    "\n",
    "__`MIDS w266: Natural Language Processing and Deep Learning | UC Berkeley School of Information | Summer 2019`__\n",
    "\n",
    "_Team members_\n",
    "\n",
    "  - __Dan Price__, danprice@ischool.berkeley.edu\n",
    "  - __Shiraz Chakraverty__, schakraverty@berkeley.edu\n",
    "\n",
    "  \n",
    "## Table of Contents\n",
    "\n",
    "[1.Abstract](#1.-Abstract)\n",
    "\n",
    "[2.Introduction](#2.-Introduction)\n",
    "\n",
    "[3.Background](#3.-Background)\n",
    "\n",
    "[3.EDA and discussion of challenges](#3.-EDA-and-discussion-of-challenges)\n",
    "\n",
    "[4.Methods (design and implementation)](#4.-Methods)\n",
    "\n",
    "[5. Application of New Concepts](#5.-Application-of-New-Concepts)\n",
    "\n",
    "[References](#6.-References)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Please render this notebook with `jupyter` or `nbviewer`. The github notebook viewer does not render all equations correctly.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Abstract\n",
    "\n",
    "\n",
    "\"CD sales are plummeting, and vinyl sales have plateaued after rising to their greatest peak since the 1990s, but that doesn't mean that people have stopped listening to music. With the rise of streaming music, people are listening as much as ever, in their homes, offices, or any other location where their devices can connect to the internet.\" - Says PCMag<sup>[1]</sup>\n",
    "\n",
    "Spotify<sup>[2]</sup>, happens to have total market share of over $25 Billion, and is one of the leaders in the music streaming space today. It has millions of songs in its database and claims at its core that it has the right music for everyone. They have invested a lot in research, especially NLP methods, starting with classification of the music based on many factors including tempo, acoustics, energy, danceability etc. to answer that most important and stressful first impression question: What is your favorite type of music?\n",
    "\n",
    "Companies like spotify are surviving based on more and more nuanced music classification, either to be able to place the right recommendations to their customers or simply as a product (for example Shazam). Thus finding out at scale, the music genres is the most fundamental step in moving towards a personal listening experience."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Introduction\n",
    "\n",
    "Various academic and industry teams have tried approaches to this space. Efforts to understand music, both sonically and semantically through lyrics and metadata, have coalesced in a subfield known as Music Information Retrieval (MIR). No single effort has been very successful in finding a stable method which performs significantly well to tackle the lyrical genre classification problem. SVM, KNN and Naive Bayes have all been used in lyrical classification but they all have very low accuracy. We would like to explore the application of new and emerging models to the task.\n",
    "\n",
    "In the field of Natural Language Processing, the classification of music genres based on lyrics is a challenging task. Machine understanding of language in general is complex. We cannot yet fully understand how the human brain does it but many strides have been made. With that understanding, newer and emerging algorithms and word embeddings are able to offer classifications useful for organizations doing language tasks at a large scale. \n",
    "\n",
    "We would like to explore advantages and disadvantages of several methods in papers we have selected and report our observations, learnings and a recommendation. With the focus of deep learning, it is clear that Neural Networks tend to work better than previously used models. We would like to explore this path and provide some comparative analysis. \n",
    "\n",
    "The dataset for this problem is hard to come by  due to copyright and other original content protection requirements. The search for more examples continues, in the meantime we have we found a data set in Kaggle which is suitable to get started with model development.\n",
    "\n",
    "The initial dataset is downloadable as a comma delimited file. The columns in the file are as follows:\n",
    "`index,song,year,artist,genre,lyrics`\n",
    "    \n",
    "We are particularly interested in the text in the lyrics column. However, we may find ways to utilize other columns as features. The lyrics are a string with carriage returns denoting an end of line. Statistics specific to the overall structure of the lyrics, such as line length, may add value to the classification task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. EDA and discussion of challenges\n",
    "\n",
    "After processing the lyrics we analysed the data and identified the features. One of the main problems with this challange is that many song lyrics get mistaken with a genre that they don't belong to. In this experiment, the goal was to build a classifier able to classify lyrics into distinct categories, Algorithms able to identify  lyrics are obviously useful to maybe filter its access to specific audience. As Christian music examples exist in all the major popular music styles (from pop to heavy metal), it is a good example of kind of songs that can benefit from such an algorithm, the most obvious way of identifying Christian music is by the lyrics.\n",
    "\n",
    "While linear and kernel models rely on good hand selected features, deep learning architectures attempt to prevent this by letting the model learn important features themselves. However, not much research has looked into the performance of these deep learning methods with respect to the genre classification task on lyrics. Here, we attempt to understand this situation by extending the deep learning ideas on text classification to the particular\n",
    "case of lyrics. Previous non-neural lyrical classifiers struggled to achieve a classification accuracy any higher than 50%. We can see evidence of this here.\n",
    "\n",
    "We used Spark to analyse the data and visualized the data. This analysis helped us understand the features of the data that would be most useful for the task in our hand. We evaluated the average length of lyrics in each genre, and we had an interesting insight, Hip-Hop songs were longer as compared to the other genres. And the rest of the genres had almost similar lengths. \n",
    "\n",
    "An important idea in NLP is the use of dense vectors to represent words. To learn these word vectors a variety of methods have been proposed. A successful methodology proposes that similar words have similar context and thus that these vectors should be learnt through their context, such as in the word2vec model propose the GloVe method\n",
    "which combines global matrix factorisation and local context window. We tried using this method and did not find a major improvement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook Set-Up\n",
    "\n",
    "The following setup demonstrates two distinct yet valuable approaches. We have used the RDD API as well as the Spark 2.0 DataFrame and ML API in this project. The following are the setup elements, in brief:\n",
    "\n",
    "(1) Python and Spark libraries - \n",
    "\n",
    "`NumPy` Provides\n",
    ",\n",
    "  1. An array object of arbitrary homogeneous items\n",
    "  2. Fast mathematical operations over arrays\n",
    "  3. Linear Algebra, Fourier Transforms, Random Number Generation\n",
    "\n",
    "`Pandas` Provides,\n",
    "\n",
    "  1. Intelligent label-based slicing, fancy indexing, and subsetting of large data sets.\n",
    "  2. Intuitive merging and joining data sets.\n",
    "  3. Flexible reshaping and pivoting of data sets.\n",
    "\n",
    "`Matplotlib` Provides a MATLAB-like way of plotting. `pyplot` is mainly intended for interactive plots and simple cases of programmatic\n",
    "plot generation::\n",
    "\n",
    "`SparkSession` is the entry point to programming Spark with the Dataset and DataFrame API. A SparkSession can be used create `DataFrame` as tables, execute SQL over tables, cache tables, and read parquet files.\n",
    "\n",
    "For brevity, we will not list out all the libraries and their functions, this can be easily requested by executing `[name of library]??`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "def fxn():\n",
    "    warnings.warn(\"deprecated\", DeprecationWarning)\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    fxn()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "# This tells matplotlib not to try opening a new window for each plot.\n",
    "%matplotlib inline\n",
    "\n",
    "# General libraries.\n",
    "import time\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import math\n",
    "import csv\n",
    "import os\n",
    "import sys\n",
    "from tabulate import tabulate\n",
    "import seaborn as sns\n",
    "from nltk.corpus import wordnet\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "#from nltk.stem.porter import *\n",
    "from stemming.porter2 import stem\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import sys\n",
    "from sklearn.pipeline import Pipeline\n",
    "import pickle\n",
    "from sklearn.externals import joblib\n",
    "from sklearn import preprocessing\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Dense, Input, GlobalMaxPooling1D, Flatten, Dropout\n",
    "from keras.layers import Conv1D, MaxPooling1D, Embedding\n",
    "from keras.models import Model\n",
    "from keras import optimizers\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from collections import Counter, defaultdict\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-07-28 19:48:27--  https://storage.googleapis.com/bert_models/2018_10_18/uncased_L-12_H-768_A-12.zip\n",
      "Resolving storage.googleapis.com (storage.googleapis.com)... 209.85.200.128, 2607:f8b0:4001:c08::80\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|209.85.200.128|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 407727028 (389M) [application/zip]\n",
      "Saving to: ‘uncased_L-12_H-768_A-12.zip.1’\n",
      "\n",
      "uncased_L-12_H-768_ 100%[===================>] 388.84M   279MB/s    in 1.4s    \n",
      "\n",
      "2019-07-28 19:48:28 (279 MB/s) - ‘uncased_L-12_H-768_A-12.zip.1’ saved [407727028/407727028]\n",
      "\n",
      "Archive:  uncased_L-12_H-768_A-12.zip\n",
      "   creating: uncased_L-12_H-768_A-12/\n",
      "  inflating: uncased_L-12_H-768_A-12/bert_model.ckpt.meta  \n",
      "  inflating: uncased_L-12_H-768_A-12/bert_model.ckpt.data-00000-of-00001  \n",
      "  inflating: uncased_L-12_H-768_A-12/vocab.txt  \n",
      "  inflating: uncased_L-12_H-768_A-12/bert_model.ckpt.index  \n",
      "  inflating: uncased_L-12_H-768_A-12/bert_config.json  \n",
      "bert_config.json\t\t     bert_model.ckpt.index  vocab.txt\n",
      "bert_model.ckpt.data-00000-of-00001  bert_model.ckpt.meta\n"
     ]
    }
   ],
   "source": [
    "!wget https://storage.googleapis.com/bert_models/2018_10_18/uncased_L-12_H-768_A-12.zip\n",
    "!unzip uncased_L-12_H-768_A-12.zip\n",
    "!ls 'uncased_L-12_H-768_A-12'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## must install following libraries\n",
    "## pip install bert-tensorflow\n",
    "## pip install tensorflow_hub\n",
    "## verify these are installed before\n",
    "## proceeding to using the BERT library\n",
    "from datetime import datetime\n",
    "import bert\n",
    "from bert import run_classifier\n",
    "from bert import optimization\n",
    "from bert import tokenization\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow import keras\n",
    "VOCAB_FILE= \"uncased_L-12_H-768_A-12/vocab.txt\"\n",
    "INIT_CHECKPOINT = \"uncased_L-12_H-768_A-12/bert_model.ckpt\"\n",
    "CONFIG_FILE = \"uncased_L-12_H-768_A-12/bert_config.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store path to notebook\n",
    "PWD = !pwd\n",
    "PWD = PWD[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. EDA and discussion of challenges\n",
    "\n",
    "__[section needs to be updated]__\n",
    "\n",
    "\n",
    "The goal of our EDA is to characterize the dimensionality and distribution of our data. While dependent variable in our dataset tells us that the problem at hand can be solved using a binary classification algorithm, EDA helps us confirm model selection and evaluate options for a scalable solution in the Map-Reduce framework. More specifically, we will explore the data to identify the following:\n",
    "\n",
    "- What is the total number of dimensions?\n",
    "- What is the distribution of dimensions?\n",
    "- Does the dataset conform to the assumptions of a Linear Regression statistcal model?\n",
    "- What is Receiver Operating Characteristic (ROC) curve with all features (i.e., without any feature hashing)?\n",
    "\n",
    "\n",
    "### Loading the Dataset\n",
    "\n",
    "In a limited scope and timeframe we can use this chunk of data that represents roughly a week's worth of click through logs captured. From the raw data, we can see that the dataset consists of text delimited by tabs. The first entry is the label (0 or 1, where 0 means the user didn't click on the given ad), while the rest are features associated with the ad. While we can imagine that there could be a whole host of features like device types, browser types, time of day, date, advertisers, ad, platform, company...but we cannot see any of these labels or the underlying values, these have been changed and hence we cannot `infer` based on any domain knowledge, hence the goal in this project will be more on `prediction performance` and `distributed computing scalability and design efficiency`.\n",
    "\n",
    "Data file strip :  ```0\t\t0\t14\t6\t7132\t171\t2\t2\t6\t\t1\t\t6\t05db9164\t38a947a1\te88a1d4c\t8eb9aec7\t25c83c98\tfbad5c96\t3fd38f3b\t```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1) Create a storage directory, download and extract the tarball. This section below is to capture the data we have been provided. In production, we will likely grep this from a kafka stream dumping files into a hdfs storage location from where we can safely load the data into our Spark clusters. However before doing these, we still need to capture these files, and be able to perform some basic operations prior to using the Spark application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying gs://266-schakraverty/lyrics.tar...\n",
      "- [1/1 files][309.6 MiB/309.6 MiB] 100% Done                                    \n",
      "Operation completed over 1 objects/309.6 MiB.                                    \n"
     ]
    }
   ],
   "source": [
    "#copy file from bucket\n",
    "!gsutil -m cp gs://266-schakraverty/lyrics.tar ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./._lyrics.csv\r\n",
      "lyrics.csv\r\n"
     ]
    }
   ],
   "source": [
    "# Run Once - In production, this will move to the data pipeline\n",
    "# make a data folder & download zipped datafile\n",
    "#!mkdir data\n",
    "#!gunzip data/lyrics.tar.gz\n",
    "!tar -xvf lyrics.tar\n",
    "#!cp lyrics.csv data/lyrics.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2) Count the total size of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9357041 lyrics.csv\r\n"
     ]
    }
   ],
   "source": [
    "#Count the number of records in the raw data\n",
    "!wc -l lyrics.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Records: 362237\n"
     ]
    }
   ],
   "source": [
    "lyrics_sample = pd.read_csv('lyrics.csv')\n",
    "print('Number of Records:',len(lyrics_sample))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(3) Preporcessing the dataset - Perform a list of preprocessing steps. Each step is described below with comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pre-processing\n",
    "def data_cleanup():\n",
    "\n",
    "#Cleaning up the data\n",
    "    with open('lyrics.csv', 'r') as inp, open('lyrics_out.csv', 'w') as out:\n",
    "        writer = csv.writer(out)\n",
    "        for row in csv.reader(inp):\n",
    "            writer.writerow(row)\n",
    "\n",
    "def multi_class_data():\n",
    "\tdata_cleanup()\n",
    "\n",
    "\tdf = pd.read_csv('lyrics_out.csv')\n",
    "\n",
    "\t#add a new column with word count of the lyrics of a song\n",
    "\tdf['word_count'] = df['lyrics'].str.split( ).str.len()\n",
    "\n",
    "\tdf[\"lyrics\"] = df['lyrics'].str.lower()\n",
    "\n",
    "\t#remove rows with lyrics count less than 100\n",
    "\n",
    "\t#df = df[df['genre']!=\"Pop\"]\n",
    "\tdf = df[df['genre']!=\"Folk\"]\n",
    "\t#df = df[df['genre']!=\"Jazz\"]\n",
    "\tdf = df[df['genre']!=\"R&B\"]\n",
    "\tdf = df[df['genre']!=\"Indie\"]\n",
    "\tdf = df[df['genre']!=\"Electronic\"]\n",
    "\tdf = df[df['genre']!=\"Metal\"]\n",
    "\n",
    "\tdf = df[df['word_count'] > 100]\n",
    "\n",
    "\tdf = df.groupby('genre').head(1000)\n",
    "\t#replace carriage returns\n",
    "\tdf = df.replace({'\\n': ' '}, regex=True)\n",
    "\n",
    "\tdel df['song'],df['year'],df['artist'],df['word_count']\n",
    "\tprint (df.head())\n",
    "\n",
    "\tdf.to_csv('lyrics_final.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   index genre                                             lyrics\n",
      "0      0   Pop  oh baby, how you doing? you know i'm gonna cut...\n",
      "1      1   Pop  playin' everything so easy, it's like you seem...\n",
      "2      2   Pop  if you search for tenderness it isn't hard to ...\n",
      "3      3   Pop  oh oh oh i, oh oh oh i [verse 1:] if i wrote a...\n",
      "4      4   Pop  party the people, the people the party it's po...\n",
      "completed job in: 28.995556116104126 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "multi_class_data()\n",
    "end = time.time()\n",
    "print(\"completed job in:\",end - start,\"seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__explain what is being done above]__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process():\n",
    "\n",
    "\tprint(\"Processing the data...\")\n",
    "\tdf = pd.read_csv('lyrics_final.csv')\n",
    "\tdf.replace('?', -9999999, inplace=True)\n",
    "\n",
    "\tdf.drop(['index'],1, inplace=True)\n",
    "\t\n",
    "\t#dict_genres={'Rock':1, 'Country':2, 'Hip-Hop':3, 'Pop':4, 'Jazz':5}\n",
    "    \n",
    "\tdict_genres={genre:index for index,genre in enumerate(df.genre.value_counts().keys())}\n",
    "    \n",
    "\tlabels = []\n",
    "\ttext = []\n",
    "\tfor index, row in df.iterrows():\n",
    "\t\tlabels.append(row[0])\n",
    "\t\twords = row[1].split()\n",
    "\t\ttext.append(row[1])\n",
    "\t\t#text.append(words)\n",
    "\t#stemming\n",
    "\ttext = [[stem(word) for word in sentence.split(\" \")] for sentence in text]\n",
    "\ttext = [\" \".join(sentence) for sentence in text]\n",
    "\n",
    "\tprint(\"Data processing done!!\")\n",
    "\treturn text,labels,dict_genres\n",
    "\n",
    "\n",
    "def build_dataset(text,labels):\n",
    "\t#text, labels = pre_process()\n",
    "\t\n",
    "\tprint(\"Total songs: %s\"%(len(labels)))\n",
    "\tcountVec = TfidfVectorizer(stop_words = 'english', sublinear_tf=True)\n",
    "\n",
    "\t#countVec = CountVectorizer(stop_words = 'english')\n",
    "\n",
    "\tx_train, x_test, y_train, y_test = train_test_split(text,labels,test_size=0.2)\n",
    "\n",
    "\t#Creating tf-idf vector for the documents\n",
    "\n",
    "\tx_trainCV = countVec.fit_transform(x_train)\n",
    "\tjoblib.dump(countVec, \"tfidf_vectorizer.pickle\")\n",
    "\n",
    "\tx_testCV = countVec.transform(x_test)\n",
    "\n",
    "    \n",
    "\tx_train = x_trainCV.toarray()\n",
    "\tx_test = x_testCV.toarray()\n",
    "\n",
    "\tx_train = preprocessing.normalize(x_train)\n",
    "\tx_train = preprocessing.scale(x_train)\n",
    "\t\n",
    "\tx_test = preprocessing.normalize(x_test)\n",
    "\tx_test = preprocessing.scale(x_test)\n",
    "    \n",
    "    \n",
    "\tjoblib.dump(countVec, \"tfidf_vectorizer.pickle\")\n",
    "\n",
    "\tprint(\"x_train: %s, x_test: %s, y_train: %s, y_test: %s\"%(len(x_train),len(x_test),len(y_train),len(y_test)))\t\n",
    "\treturn x_train,x_test,y_train,y_test\n",
    "\n",
    "def train(input1,x_train,x_test,y_train,y_test):\n",
    "\tf = open(\"multiclass.txt\", \"w\")\n",
    "\tif input1 == \"bnb\":\n",
    "\t\tprint(\"Bernoulli Naive Bayes Classifier\")\n",
    "\t\tbnb = BernoulliNB()\n",
    "\t\tbnb.fit(x_train,y_train)\n",
    "\t\taccuracy = bnb.score(x_test,y_test)\n",
    "\t\tprint(\"accuracy for bernoulli naive bayes: %s\"%(accuracy))\n",
    "\t\tf.write(\"accuracy for bernoulli naive bayes: %s \\n\"%(accuracy))\n",
    "\t\n",
    "\tif input1 == \"dt\":\n",
    "\t\tprint(\"Decision Tree Classifier\")\n",
    "\t\tdt = DecisionTreeClassifier()\n",
    "\t\tdt.fit(x_train,y_train)\n",
    "\t\taccuracy = dt.score(x_test,y_test)\n",
    "\t\tprint(\"accuracy for Decision Tree: %s\"%(dt.score(x_test,y_test)))\n",
    "\t\tf.write(\"accuracy for decision tree: %s \\n\"%(accuracy))\n",
    "\t\n",
    "\tif input1 == \"mlp\":\n",
    "\t\tprint(\"Multi Layer Perceptron Classifier\")\n",
    "\t\t#Training and Testing on SCikit Neural Network library\n",
    "\t\tneural = MLPClassifier()\n",
    "\t\tneural.fit(x_train,y_train)\n",
    "\n",
    "\t\tjoblib.dump(neural, \"classifier.pickle\")\n",
    "\n",
    "\t\taccuracy = neural.score(x_test, y_test)\n",
    "\t\tprint(\"accuracy for Neural Network: %s\"%(accuracy))\n",
    "\t\t\n",
    "\tif input1 == \"rf\":\n",
    "\t\tprint(\"Random Forest Classifier\")\n",
    "\t\trf = RandomForestClassifier(n_estimators=100,max_features=\"sqrt\").fit(x_train,y_train)\n",
    "\t\tjoblib.dump(rf, \"classifier.pickle\")\n",
    "\t\taccuracy = rf.score(x_test, y_test)\n",
    "\t\t\n",
    "\t\tprint(\"accuracy for Random Forest: %s\"%(accuracy))\n",
    "\t\tf.write(\"accuracy for Random Forest: %s \\n\"%(accuracy))\n",
    "\t\n",
    "\tf.close()\n",
    "\n",
    "def test(input_string):\n",
    "\n",
    "\tvectorizer = joblib.load(\"tfidf_vectorizer.pickle\")\n",
    "\tclassifier = joblib.load(\"classifier.pickle\")\n",
    "\t\n",
    "\ttr = vectorizer.transform(input_string)\n",
    "\n",
    "\tpredictions = classifier.predict(tr)\n",
    "\tprint(predictions[0])\n",
    "\treturn predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing the data...\n",
      "Data processing done!!\n",
      "text: 7000 labels: 7000\n",
      "completed in : 34.714802503585815 seconds\n",
      "{'Rock': 1, 'Not Available': 6, 'Pop': 0, 'Jazz': 4, 'Hip-Hop': 2, 'Country': 3, 'Other': 5}\n"
     ]
    }
   ],
   "source": [
    "# process the lyrics, convert into train and test\n",
    "start = time.time()\n",
    "text, labels, genre_dict = pre_process()\n",
    "labels = labels[:len(text)]\n",
    "print('text:',len(text),'labels:',len(labels))\n",
    "end = time.time()\n",
    "print(\"completed in :\",end - start,\"seconds\")\n",
    "print(genre_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total songs: 7000\n",
      "x_train: 5600, x_test: 1400, y_train: 5600, y_test: 1400\n",
      "completed in : 27.514610052108765 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "x_train, x_test, y_train, y_test = build_dataset(text, labels)\n",
    "end = time.time()\n",
    "print(\"completed in :\",end - start,\"seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Methods\n",
    "\n",
    "We have taken few different approaches to the problem, resulting in multiple models. In our main baseline approach we use term frequency and inverse document frequency as our feature vectors and the genre classes as our labels to identify. \n",
    "\n",
    "In order to demonstrate the baseline complexity, We developed Naive Bayes, Random Forest, Support Vector machine and Multi Layer Perceptron model to classify the songs into multiple classes. We have also normalized the vector after applying the Count Vectorizer and Tf-Idf Weighing scheme.\n",
    "\n",
    "Word2Vec\n",
    "\n",
    "Next, we used the word vectors (word2vec) to represent our lyrical text. These semantic style vectors preserve most of the relevant information in a text while having relatively low dimensionality. Word2vec is a group of related models that are used to produce word embeddings. These models are shallow, two-layer neural networks that are trained to reconstruct linguistic contexts of words. \n",
    "\n",
    "Word2vec takes as its input a large corpus of text and produces a vector space, typically of several hundred dimensions, with each unique word in the corpus being assigned a corresponding vector in the space. Word vectors are positioned in the vector space such that words that share common contexts in the corpus are located in close proximity to one another in the space.\n",
    "\n",
    "Word2vec was created by a team of researchers led by Tomas Mikolov at Google and patented. The algorithm has been subsequently analysed and explained by other researchers. Embedding vectors created using the Word2vec algorithm have many advantages compared to earlier algorithms such as latent semantic analysis. \n",
    "\n",
    "Naive Bayes: Implemented Bernoulli and Multinomial Naive Bayes, Support Vector Machine: Used the linear kernel, Logistic Regression, Decision Tree, Random Forest: Used 100 trees and the majority of all the classifications are the result, MultiLayer Perceptron Model: Experimented with various activation functions and hidden layers, Extra Trees Classifier: Used this algorithm to test with word2vec feature vectors: Used this algorithm to test with word2vec feature vectors. We decided to remove models that did not proove to be practically useful - either they took far too long to train or they performed very poorly.\n",
    "\n",
    "We used a Convolutional Neural Network to classify the songs into their respective genres. We used pre-trained glove vectors for this model. The glove model we used is Google Glove 6B vector 100d. We have implemented 1 CNN models using Keras library: convolution model: layer is convoluted and maxpool layer.\n",
    "\n",
    "As we have since learned that,\n",
    "\n",
    "Context-free models such as word2vec or GloVe generate a single word embedding representation for each word in the vocabulary. For example, the word “bank” would have the same context-free representation in “bank account” and “bank of the river.”\n",
    "\n",
    "Contextual models instead generate a representation of each word that is based on the other words in the sentence. Contextual representations can further be unidirectional or bidirectional. For example, in the sentence “I accessed the bank account,” a unidirectional contextual model would represent “bank” based on “I accessed the” but not “account.” However, BERT represents “bank” using both its previous and next context — “I accessed the … account” — starting from the very bottom of a deep neural network, making it deeply bidirectional.\n",
    "\n",
    "Hence we decided to download a pre-trained BERT model and use for our multiclass classification problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Baseline models__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bernoulli Naive Bayes Classifier\n",
      "accuracy for bernoulli naive bayes: 0.44785714285714284\n",
      "completed in: 4.013340711593628 seconds\n",
      "Decision Tree Classifier\n",
      "accuracy for Decision Tree: 0.4007142857142857\n",
      "completed in: 72.38715481758118 seconds\n",
      "Multi Layer Perceptron Classifier\n",
      "accuracy for Neural Network: 0.45714285714285713\n",
      "completed in: 442.3939027786255 seconds\n",
      "Random Forest Classifier\n",
      "accuracy for Random Forest: 0.48142857142857143\n",
      "completed in: 97.170969247818 seconds\n"
     ]
    }
   ],
   "source": [
    "input_param = [\"bnb\",\"dt\",\"mlp\",\"rf\"]\n",
    "for i in input_param:\n",
    "    start = time.time()\n",
    "    train(i,x_train,x_test,y_train,y_test)\n",
    "    end = time.time()\n",
    "    print(\"completed in:\",end - start,\"seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Method 2 - GloVe: Global Vectors for Word Representation with standard algorithms__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "##start method 2\n",
    "df = pd.read_csv('lyrics_final.csv')\n",
    "!mkdir genres_data\n",
    "!mkdir genres_data/pop\n",
    "!mkdir genres_data/rock\n",
    "!mkdir genres_data/jazz\n",
    "!mkdir genres_data/country\n",
    "!mkdir genres_data/hiphop\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "\tif row[1] == \"Pop\":\n",
    "\t\twith open(\"genres_data/pop/%s\"%(row[0]), \"a\") as pop_file:\n",
    "\t\t\tpop_file.write(row[2])\n",
    "\n",
    "\tif row[1] == \"Rock\":\n",
    "\t\twith open(\"genres_data/rock/%s\"%(row[0]), \"a\") as rock_file:\n",
    "\t\t\trock_file.write(row[2])\n",
    "\n",
    "\tif row[1] == \"Jazz\":\n",
    "\t\twith open(\"genres_data/jazz/%s\"%(row[0]), \"a\") as jazz_file:\n",
    "\t\t\tjazz_file.write(row[2])\n",
    "\n",
    "\tif row[1] == \"Country\":\n",
    "\t\twith open(\"genres_data/country/%s\"%(row[0]), \"a\") as country_file:\n",
    "\t\t\tcountry_file.write(row[2])\n",
    "\n",
    "\tif row[1] == \"Hip-Hop\":\n",
    "\t\twith open(\"genres_data/hiphop/%s\"%(row[0]), \"a\") as hiphop_file:\n",
    " \t\t\thiphop_file.write(row[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/sh: wget: command not found\n",
      "/bin/sh: wget: command not found\n"
     ]
    }
   ],
   "source": [
    "## Run ONCE ONLY - ONCE RUN, The Files will be saved for future peipeline\n",
    "\n",
    "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
    "!wget http://nlp.stanford.edu/data/glove.840B.300d.zip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  glove.6B.zip\n",
      "  inflating: glove.6B.50d.txt        \n",
      "  inflating: glove.6B.100d.txt       \n",
      "  inflating: glove.6B.200d.txt       \n",
      "  inflating: glove.6B.300d.txt       \n",
      "Archive:  glove.840B.300d.zip\n",
      "  inflating: glove.840B.300d.txt     \n"
     ]
    }
   ],
   "source": [
    "## Also run ONCE when setting up a new Cluster.\n",
    "!unzip glove.6B.zip\n",
    "!unzip glove.840B.300d.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total examples 7000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/schakraverty/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py:56: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.vectors instead).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model            score\n",
      "-------------  -------\n",
      "bern_nb         0.3811\n",
      "bern_nb_tfidf   0.3811\n",
      "mult_nb         0.3849\n",
      "mult_nb_tfidf   0.3349\n",
      "svc             0.3554\n",
      "svc_tfidf       0.3960\n"
     ]
    }
   ],
   "source": [
    "# Song word to vector\n",
    "\n",
    "GLOVE_6B_50D_PATH = \"glove.6B.50d.txt\"\n",
    "GLOVE_840B_300D_PATH = \"glove.840B.300d.txt\"\n",
    "\n",
    "f = open(\"multiclass.txt\", \"w\")\n",
    "\n",
    "df = pd.read_csv('lyrics_final.csv')\n",
    "df.replace('?', -9999999, inplace=True)\n",
    "\n",
    "df.drop(['index'],1, inplace=True)\n",
    "labels = []\n",
    "text = []\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    labels.append(row[0])\n",
    "    words = row[1].split()\n",
    "    text.append(words)\n",
    "\n",
    "#print(labels)\n",
    "\n",
    "X, y = np.array(text), np.array(labels)\n",
    "print(\"total examples %s\" % len(y))\n",
    "\n",
    "with open(GLOVE_6B_50D_PATH, \"rb\") as lines:\n",
    "    word2vec = {line.split()[0]: np.array(map(float, line.split()[1:]))\n",
    "               for line in lines}\n",
    "\n",
    "# reading glove files, this may take a while\n",
    "# we're reading line by line and only saving vectors\n",
    "# that correspond to words from our training set\n",
    "\n",
    "\n",
    "glove_small = {}\n",
    "all_words = set(w for words in X for w in words)\n",
    "with open(GLOVE_6B_50D_PATH, \"rb\") as infile:\n",
    "    for line in infile:\n",
    "        parts = line.split()\n",
    "        word = parts[0]\n",
    "        nums = map(float, parts[1:])\n",
    "        if word in all_words:\n",
    "            glove_small[word] = np.array(nums)\n",
    "            \n",
    "glove_big = {}\n",
    "with open(GLOVE_840B_300D_PATH, \"rb\") as infile:\n",
    "    for line in infile:\n",
    "        parts = line.split()\n",
    "        word = parts[0]\n",
    "        nums = map(float, parts[1:])\n",
    "        if word in all_words:\n",
    "            glove_big[word] = np.array(nums)\n",
    "\n",
    "# train word2vec on all the texts - both training and test set\n",
    "# we're not using test labels, just texts so this is fine\n",
    "model = Word2Vec(X, size=100, window=5, min_count=5, workers=2)\n",
    "w2v = {w: vec for w, vec in zip(model.wv.index2word, model.wv.syn0)}\n",
    "\n",
    "# start with the classics - naive bayes of the multinomial and bernoulli varieties\n",
    "# with either pure counts or tfidf features\n",
    "mult_nb = Pipeline([(\"count_vectorizer\", CountVectorizer(analyzer=lambda x: x)), (\"multinomial nb\", MultinomialNB())])\n",
    "bern_nb = Pipeline([(\"count_vectorizer\", CountVectorizer(analyzer=lambda x: x)), (\"bernoulli nb\", BernoulliNB())])\n",
    "mult_nb_tfidf = Pipeline([(\"tfidf_vectorizer\", TfidfVectorizer(analyzer=lambda x: x)), (\"multinomial nb\", MultinomialNB())])\n",
    "bern_nb_tfidf = Pipeline([(\"tfidf_vectorizer\", TfidfVectorizer(analyzer=lambda x: x)), (\"bernoulli nb\", BernoulliNB())])\n",
    "# SVM - which is supposed to be more or less state of the art \n",
    "# http://www.cs.cornell.edu/people/tj/publications/joachims_98a.pdf\n",
    "svc = Pipeline([(\"count_vectorizer\", CountVectorizer(analyzer=lambda x: x)), (\"linear svc\", SVC(kernel=\"linear\"))])\n",
    "svc_tfidf = Pipeline([(\"tfidf_vectorizer\", TfidfVectorizer(analyzer=lambda x: x)), (\"linear svc\", SVC(kernel=\"linear\"))])\n",
    "\n",
    "\n",
    "all_models = [\n",
    "    (\"mult_nb\", mult_nb),\n",
    "    (\"mult_nb_tfidf\", mult_nb_tfidf),\n",
    "    (\"bern_nb\", bern_nb),\n",
    "    (\"bern_nb_tfidf\", bern_nb_tfidf),\n",
    "    (\"svc\", svc),\n",
    "    (\"svc_tfidf\", svc_tfidf)\n",
    "]\n",
    "scores = sorted([(name, cross_val_score(model, X, y, cv=5).mean()) \n",
    "                 for name, model in all_models])\n",
    "print(tabulate(scores, floatfmt=\".4f\", headers=(\"model\", 'score')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the performance still does not cross about 40%. From our standpoint, classification by lyrics will always be inherently flawed by vague genre boundaries with many genres borrowing lyrics and styles from one another. For example one merely need consider cover songs which utilise the same lyrics but produce songs in vastly different genres, or songs which have no lyrical content. \n",
    "\n",
    "To produce a state of the art classifier it is evident that the classifier must take into account more than just the lyrical content of the song. Audio data typically performs the strongest and further research could look into employing other models to the audio and symbolic data and combining with the lyrics to build a stronger classifier. Lyrics typically perform stronger on the sentiment analysis classification task and further research could employ the more complex models to this problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexing word vectors.\n",
      "Found 400000 word vectors.\n",
      "Processing text dataset\n",
      "Found 5000 texts.\n",
      "Found 39061 unique tokens.\n",
      "Shape of data tensor: (5000, 1000)\n",
      "Shape of label tensor: (5000, 5)\n",
      "Preparing embedding matrix.\n",
      "Training model.\n",
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/100\n",
      "4000/4000 [==============================] - 8s 2ms/step - loss: 1.6036 - acc: 0.2915 - val_loss: 1.5410 - val_acc: 0.3380\n",
      "Epoch 2/100\n",
      "4000/4000 [==============================] - 7s 2ms/step - loss: 1.4418 - acc: 0.3615 - val_loss: 1.4431 - val_acc: 0.3490\n",
      "Epoch 3/100\n",
      "4000/4000 [==============================] - 7s 2ms/step - loss: 1.3474 - acc: 0.4015 - val_loss: 1.3419 - val_acc: 0.3970\n",
      "Epoch 4/100\n",
      "4000/4000 [==============================] - 7s 2ms/step - loss: 1.2889 - acc: 0.4327 - val_loss: 1.2167 - val_acc: 0.4810\n",
      "Epoch 5/100\n",
      "4000/4000 [==============================] - 7s 2ms/step - loss: 1.2308 - acc: 0.4607 - val_loss: 1.2241 - val_acc: 0.4850\n",
      "Epoch 6/100\n",
      "4000/4000 [==============================] - 7s 2ms/step - loss: 1.1869 - acc: 0.4833 - val_loss: 1.1909 - val_acc: 0.4960\n",
      "Epoch 7/100\n",
      "4000/4000 [==============================] - 7s 2ms/step - loss: 1.1460 - acc: 0.5045 - val_loss: 1.1378 - val_acc: 0.5320\n",
      "Epoch 8/100\n",
      "4000/4000 [==============================] - 7s 2ms/step - loss: 1.0990 - acc: 0.5365 - val_loss: 1.1034 - val_acc: 0.5410\n",
      "Epoch 9/100\n",
      "4000/4000 [==============================] - 7s 2ms/step - loss: 1.0697 - acc: 0.5475 - val_loss: 1.2004 - val_acc: 0.4810\n",
      "Epoch 10/100\n",
      "4000/4000 [==============================] - 7s 2ms/step - loss: 1.0137 - acc: 0.5820 - val_loss: 1.3844 - val_acc: 0.4610\n",
      "Epoch 11/100\n",
      "4000/4000 [==============================] - 7s 2ms/step - loss: 0.9831 - acc: 0.5962 - val_loss: 1.2259 - val_acc: 0.5250\n",
      "Epoch 12/100\n",
      "4000/4000 [==============================] - 7s 2ms/step - loss: 0.9721 - acc: 0.5935 - val_loss: 1.0792 - val_acc: 0.5540\n",
      "Epoch 13/100\n",
      "4000/4000 [==============================] - 7s 2ms/step - loss: 0.8795 - acc: 0.6470 - val_loss: 1.1634 - val_acc: 0.5490\n",
      "Epoch 14/100\n",
      "4000/4000 [==============================] - 7s 2ms/step - loss: 0.8712 - acc: 0.6478 - val_loss: 1.1364 - val_acc: 0.5370\n",
      "Epoch 15/100\n",
      "4000/4000 [==============================] - 7s 2ms/step - loss: 0.8074 - acc: 0.6825 - val_loss: 1.2264 - val_acc: 0.5320\n",
      "Epoch 16/100\n",
      "4000/4000 [==============================] - 7s 2ms/step - loss: 0.7770 - acc: 0.6957 - val_loss: 1.0617 - val_acc: 0.5990\n",
      "Epoch 17/100\n",
      "4000/4000 [==============================] - 7s 2ms/step - loss: 0.7169 - acc: 0.7288 - val_loss: 1.3255 - val_acc: 0.4880\n",
      "Epoch 18/100\n",
      "4000/4000 [==============================] - 7s 2ms/step - loss: 0.6685 - acc: 0.7530 - val_loss: 1.1113 - val_acc: 0.5880\n",
      "Epoch 19/100\n",
      "4000/4000 [==============================] - 7s 2ms/step - loss: 0.6163 - acc: 0.7792 - val_loss: 1.2424 - val_acc: 0.5430\n",
      "Epoch 20/100\n",
      "4000/4000 [==============================] - 7s 2ms/step - loss: 0.5867 - acc: 0.7765 - val_loss: 1.4532 - val_acc: 0.5110\n",
      "Epoch 21/100\n",
      "4000/4000 [==============================] - 7s 2ms/step - loss: 0.5417 - acc: 0.8010 - val_loss: 1.1196 - val_acc: 0.5820\n",
      "Epoch 22/100\n",
      "4000/4000 [==============================] - 8s 2ms/step - loss: 0.4869 - acc: 0.8235 - val_loss: 1.1929 - val_acc: 0.5740\n",
      "Epoch 23/100\n",
      "4000/4000 [==============================] - 7s 2ms/step - loss: 0.4438 - acc: 0.8420 - val_loss: 1.3987 - val_acc: 0.5680\n",
      "Epoch 24/100\n",
      "4000/4000 [==============================] - 7s 2ms/step - loss: 0.3933 - acc: 0.8563 - val_loss: 1.8829 - val_acc: 0.4770\n",
      "Epoch 25/100\n",
      "4000/4000 [==============================] - 7s 2ms/step - loss: 0.4352 - acc: 0.8588 - val_loss: 1.3953 - val_acc: 0.5730\n",
      "Epoch 26/100\n",
      "4000/4000 [==============================] - 7s 2ms/step - loss: 0.4174 - acc: 0.8630 - val_loss: 1.2604 - val_acc: 0.6050\n",
      "Epoch 27/100\n",
      "4000/4000 [==============================] - 7s 2ms/step - loss: 0.3019 - acc: 0.9050 - val_loss: 1.6077 - val_acc: 0.5370\n",
      "Epoch 28/100\n",
      "4000/4000 [==============================] - 7s 2ms/step - loss: 0.3085 - acc: 0.8898 - val_loss: 1.3483 - val_acc: 0.5880\n",
      "Epoch 29/100\n",
      "4000/4000 [==============================] - 7s 2ms/step - loss: 0.2735 - acc: 0.9133 - val_loss: 1.4922 - val_acc: 0.5720\n",
      "Epoch 30/100\n",
      "4000/4000 [==============================] - 7s 2ms/step - loss: 0.2474 - acc: 0.9167 - val_loss: 1.7418 - val_acc: 0.5620\n",
      "Epoch 31/100\n",
      "4000/4000 [==============================] - 7s 2ms/step - loss: 0.2581 - acc: 0.9175 - val_loss: 1.4859 - val_acc: 0.5890\n",
      "Epoch 32/100\n",
      "4000/4000 [==============================] - 7s 2ms/step - loss: 0.2379 - acc: 0.9185 - val_loss: 1.5564 - val_acc: 0.5740\n",
      "Epoch 33/100\n",
      "4000/4000 [==============================] - 7s 2ms/step - loss: 0.2081 - acc: 0.9317 - val_loss: 1.6863 - val_acc: 0.5700\n",
      "Epoch 34/100\n",
      "4000/4000 [==============================] - 7s 2ms/step - loss: 0.1913 - acc: 0.9368 - val_loss: 1.6867 - val_acc: 0.5960\n",
      "Epoch 35/100\n",
      "4000/4000 [==============================] - 7s 2ms/step - loss: 0.1807 - acc: 0.9437 - val_loss: 1.6187 - val_acc: 0.5410\n",
      "Epoch 36/100\n",
      "4000/4000 [==============================] - 7s 2ms/step - loss: 0.1917 - acc: 0.9447 - val_loss: 1.6870 - val_acc: 0.5590\n",
      "Epoch 37/100\n",
      "4000/4000 [==============================] - 7s 2ms/step - loss: 0.1336 - acc: 0.9565 - val_loss: 1.7720 - val_acc: 0.5830\n",
      "Epoch 38/100\n",
      "4000/4000 [==============================] - 7s 2ms/step - loss: 0.1798 - acc: 0.9463 - val_loss: 2.0283 - val_acc: 0.5290\n",
      "Epoch 39/100\n",
      "4000/4000 [==============================] - 7s 2ms/step - loss: 0.1771 - acc: 0.9373 - val_loss: 1.7931 - val_acc: 0.5640\n",
      "Epoch 40/100\n",
      "4000/4000 [==============================] - 8s 2ms/step - loss: 0.1280 - acc: 0.9663 - val_loss: 1.7863 - val_acc: 0.5750\n",
      "Epoch 41/100\n",
      "4000/4000 [==============================] - 8s 2ms/step - loss: 0.1907 - acc: 0.9535 - val_loss: 1.9310 - val_acc: 0.5670\n",
      "Epoch 42/100\n",
      "4000/4000 [==============================] - 7s 2ms/step - loss: 0.1989 - acc: 0.9437 - val_loss: 1.6881 - val_acc: 0.5680\n",
      "Epoch 43/100\n",
      "4000/4000 [==============================] - 7s 2ms/step - loss: 0.0950 - acc: 0.9730 - val_loss: 1.8776 - val_acc: 0.5800\n",
      "Epoch 44/100\n",
      "4000/4000 [==============================] - 7s 2ms/step - loss: 0.1515 - acc: 0.9527 - val_loss: 1.8562 - val_acc: 0.5640\n",
      "Epoch 45/100\n",
      "4000/4000 [==============================] - 7s 2ms/step - loss: 0.1822 - acc: 0.9617 - val_loss: 1.9684 - val_acc: 0.5820\n",
      "Epoch 46/100\n",
      "4000/4000 [==============================] - 7s 2ms/step - loss: 0.1434 - acc: 0.9557 - val_loss: 1.7413 - val_acc: 0.6020\n",
      "Epoch 47/100\n",
      "4000/4000 [==============================] - 7s 2ms/step - loss: 0.1004 - acc: 0.9680 - val_loss: 2.0293 - val_acc: 0.5480\n",
      "Epoch 48/100\n",
      "4000/4000 [==============================] - 7s 2ms/step - loss: 0.1347 - acc: 0.9587 - val_loss: 1.9280 - val_acc: 0.5830\n",
      "Epoch 49/100\n",
      "4000/4000 [==============================] - 7s 2ms/step - loss: 0.1254 - acc: 0.9607 - val_loss: 1.7932 - val_acc: 0.5890\n",
      "Epoch 50/100\n",
      "4000/4000 [==============================] - 7s 2ms/step - loss: 0.0909 - acc: 0.9710 - val_loss: 1.8477 - val_acc: 0.5750\n",
      "Epoch 51/100\n",
      "4000/4000 [==============================] - 7s 2ms/step - loss: 0.1078 - acc: 0.9753 - val_loss: 1.9444 - val_acc: 0.5950\n",
      "Epoch 52/100\n",
      "4000/4000 [==============================] - 7s 2ms/step - loss: 0.1184 - acc: 0.9680 - val_loss: 1.8941 - val_acc: 0.5860\n",
      "Epoch 53/100\n",
      "4000/4000 [==============================] - 7s 2ms/step - loss: 0.1397 - acc: 0.9615 - val_loss: 1.8778 - val_acc: 0.5730\n",
      "Epoch 54/100\n",
      "4000/4000 [==============================] - 7s 2ms/step - loss: 0.0956 - acc: 0.9738 - val_loss: 2.0736 - val_acc: 0.5750\n",
      "Epoch 55/100\n",
      "4000/4000 [==============================] - 7s 2ms/step - loss: 0.1475 - acc: 0.9605 - val_loss: 2.1342 - val_acc: 0.5830\n",
      "Epoch 56/100\n",
      "4000/4000 [==============================] - 7s 2ms/step - loss: 0.0857 - acc: 0.9750 - val_loss: 2.4238 - val_acc: 0.5770\n",
      "Epoch 57/100\n",
      "4000/4000 [==============================] - 7s 2ms/step - loss: 0.1508 - acc: 0.9640 - val_loss: 2.7377 - val_acc: 0.4980\n",
      "Epoch 58/100\n",
      "4000/4000 [==============================] - 7s 2ms/step - loss: 0.0534 - acc: 0.9852 - val_loss: 2.1070 - val_acc: 0.5670\n",
      "Epoch 59/100\n",
      "4000/4000 [==============================] - 7s 2ms/step - loss: 0.1423 - acc: 0.9665 - val_loss: 2.0620 - val_acc: 0.5750\n",
      "Epoch 60/100\n",
      "4000/4000 [==============================] - 7s 2ms/step - loss: 0.1004 - acc: 0.9685 - val_loss: 2.1296 - val_acc: 0.5750\n",
      "Epoch 61/100\n",
      "4000/4000 [==============================] - 7s 2ms/step - loss: 0.1480 - acc: 0.9555 - val_loss: 1.8194 - val_acc: 0.5700\n",
      "Epoch 62/100\n",
      "4000/4000 [==============================] - 7s 2ms/step - loss: 0.0575 - acc: 0.9830 - val_loss: 1.9767 - val_acc: 0.5770\n",
      "Epoch 63/100\n",
      "4000/4000 [==============================] - 7s 2ms/step - loss: 0.0813 - acc: 0.9760 - val_loss: 2.3871 - val_acc: 0.5350\n",
      "Epoch 64/100\n",
      "4000/4000 [==============================] - 7s 2ms/step - loss: 0.0807 - acc: 0.9745 - val_loss: 2.0450 - val_acc: 0.5910\n",
      "Epoch 65/100\n",
      "4000/4000 [==============================] - 8s 2ms/step - loss: 0.1103 - acc: 0.9708 - val_loss: 2.1933 - val_acc: 0.5650\n",
      "Epoch 66/100\n",
      "4000/4000 [==============================] - 7s 2ms/step - loss: 0.0837 - acc: 0.9732 - val_loss: 1.9777 - val_acc: 0.5820\n",
      "Epoch 67/100\n",
      "4000/4000 [==============================] - 7s 2ms/step - loss: 0.0436 - acc: 0.9838 - val_loss: 3.0113 - val_acc: 0.4720\n",
      "Epoch 68/100\n",
      "4000/4000 [==============================] - 7s 2ms/step - loss: 0.0658 - acc: 0.9795 - val_loss: 2.3354 - val_acc: 0.5770\n",
      "Epoch 69/100\n",
      "4000/4000 [==============================] - 7s 2ms/step - loss: 0.0842 - acc: 0.9738 - val_loss: 2.3108 - val_acc: 0.5730\n",
      "Epoch 70/100\n",
      "4000/4000 [==============================] - 7s 2ms/step - loss: 0.0997 - acc: 0.9753 - val_loss: 2.3759 - val_acc: 0.5930\n",
      "Epoch 71/100\n",
      "4000/4000 [==============================] - 7s 2ms/step - loss: 0.0651 - acc: 0.9795 - val_loss: 2.5912 - val_acc: 0.5260\n",
      "Epoch 72/100\n",
      "4000/4000 [==============================] - 7s 2ms/step - loss: 0.0448 - acc: 0.9852 - val_loss: 2.6486 - val_acc: 0.5480\n",
      "Epoch 73/100\n",
      "4000/4000 [==============================] - 7s 2ms/step - loss: 0.1162 - acc: 0.9750 - val_loss: 3.4645 - val_acc: 0.5150\n",
      "Epoch 74/100\n",
      "4000/4000 [==============================] - 7s 2ms/step - loss: 0.0768 - acc: 0.9775 - val_loss: 2.4447 - val_acc: 0.5360\n",
      "Epoch 75/100\n",
      "4000/4000 [==============================] - 7s 2ms/step - loss: 0.0761 - acc: 0.9762 - val_loss: 3.0724 - val_acc: 0.4880\n",
      "Epoch 76/100\n",
      "4000/4000 [==============================] - 7s 2ms/step - loss: 0.0457 - acc: 0.9858 - val_loss: 2.9125 - val_acc: 0.4860\n",
      "Epoch 77/100\n",
      "4000/4000 [==============================] - 7s 2ms/step - loss: 0.0591 - acc: 0.9832 - val_loss: 2.2592 - val_acc: 0.5580\n",
      "Epoch 78/100\n",
      "4000/4000 [==============================] - 7s 2ms/step - loss: 0.0591 - acc: 0.9798 - val_loss: 2.6638 - val_acc: 0.5570\n",
      "Epoch 79/100\n",
      "4000/4000 [==============================] - 7s 2ms/step - loss: 0.0494 - acc: 0.9873 - val_loss: 2.4559 - val_acc: 0.5740\n",
      "Epoch 80/100\n",
      "4000/4000 [==============================] - 7s 2ms/step - loss: 0.1045 - acc: 0.9732 - val_loss: 2.2506 - val_acc: 0.5670\n",
      "Epoch 81/100\n",
      "4000/4000 [==============================] - 7s 2ms/step - loss: 0.0759 - acc: 0.9795 - val_loss: 2.1771 - val_acc: 0.5860\n",
      "Epoch 82/100\n",
      "4000/4000 [==============================] - 7s 2ms/step - loss: 0.0707 - acc: 0.9778 - val_loss: 2.2534 - val_acc: 0.5690\n",
      "Epoch 83/100\n",
      "4000/4000 [==============================] - 7s 2ms/step - loss: 0.0948 - acc: 0.9745 - val_loss: 2.3690 - val_acc: 0.5780\n",
      "Epoch 84/100\n",
      "4000/4000 [==============================] - 8s 2ms/step - loss: 0.0420 - acc: 0.9870 - val_loss: 2.5445 - val_acc: 0.5890\n",
      "Epoch 85/100\n",
      "4000/4000 [==============================] - 7s 2ms/step - loss: 0.0705 - acc: 0.9785 - val_loss: 3.1578 - val_acc: 0.5290\n",
      "Epoch 86/100\n",
      "4000/4000 [==============================] - 7s 2ms/step - loss: 0.0663 - acc: 0.9800 - val_loss: 2.4364 - val_acc: 0.5660\n",
      "Epoch 87/100\n",
      "4000/4000 [==============================] - 7s 2ms/step - loss: 0.0900 - acc: 0.9755 - val_loss: 2.2837 - val_acc: 0.5640\n",
      "Epoch 88/100\n",
      "4000/4000 [==============================] - 7s 2ms/step - loss: 0.0369 - acc: 0.9888 - val_loss: 2.6344 - val_acc: 0.5550\n",
      "Epoch 89/100\n",
      "4000/4000 [==============================] - 7s 2ms/step - loss: 0.1031 - acc: 0.9690 - val_loss: 2.1309 - val_acc: 0.5620\n",
      "Epoch 90/100\n",
      "4000/4000 [==============================] - 7s 2ms/step - loss: 0.0580 - acc: 0.9808 - val_loss: 2.2132 - val_acc: 0.5800\n",
      "Epoch 91/100\n",
      "4000/4000 [==============================] - 7s 2ms/step - loss: 0.0620 - acc: 0.9820 - val_loss: 2.2638 - val_acc: 0.5910\n",
      "Epoch 92/100\n",
      "4000/4000 [==============================] - 7s 2ms/step - loss: 0.0657 - acc: 0.9815 - val_loss: 3.9838 - val_acc: 0.4730\n",
      "Epoch 93/100\n",
      "4000/4000 [==============================] - 7s 2ms/step - loss: 0.0837 - acc: 0.9772 - val_loss: 2.3451 - val_acc: 0.5770\n",
      "Epoch 94/100\n",
      "4000/4000 [==============================] - 7s 2ms/step - loss: 0.1113 - acc: 0.9758 - val_loss: 2.1990 - val_acc: 0.5590\n",
      "Epoch 95/100\n",
      "4000/4000 [==============================] - 7s 2ms/step - loss: 0.0310 - acc: 0.9890 - val_loss: 2.3791 - val_acc: 0.5370\n",
      "Epoch 96/100\n",
      "4000/4000 [==============================] - 7s 2ms/step - loss: 0.0466 - acc: 0.9862 - val_loss: 2.7654 - val_acc: 0.5590\n",
      "Epoch 97/100\n",
      "4000/4000 [==============================] - 7s 2ms/step - loss: 0.0880 - acc: 0.9785 - val_loss: 2.2818 - val_acc: 0.5660\n",
      "Epoch 98/100\n",
      "4000/4000 [==============================] - 7s 2ms/step - loss: 0.0332 - acc: 0.9880 - val_loss: 2.7424 - val_acc: 0.5600\n",
      "Epoch 99/100\n",
      "4000/4000 [==============================] - 7s 2ms/step - loss: 0.0541 - acc: 0.9855 - val_loss: 2.6991 - val_acc: 0.5610\n",
      "Epoch 100/100\n",
      "4000/4000 [==============================] - 7s 2ms/step - loss: 0.0628 - acc: 0.9795 - val_loss: 2.7610 - val_acc: 0.5580\n",
      "Test loss: 2.76096732711792\n",
      "Test accuracy: 0.558\n"
     ]
    }
   ],
   "source": [
    "BASE_DIR = ''\n",
    "GLOVE_DIR = BASE_DIR\n",
    "TEXT_DATA_DIR = os.path.join(BASE_DIR, 'genres_data')\n",
    "MAX_SEQUENCE_LENGTH = 1000\n",
    "MAX_NUM_WORDS = 20000\n",
    "EMBEDDING_DIM = 100\n",
    "VALIDATION_SPLIT = 0.2\n",
    "learning_rate = .0000001\n",
    "max_grad_norm = 1.\n",
    "dropout = 0.5\n",
    "\n",
    "# first, build index mapping words in the embeddings set\n",
    "# to their embedding vector\n",
    "\n",
    "print('Indexing word vectors.')\n",
    "\n",
    "embeddings_index = {}\n",
    "f = open(os.path.join(GLOVE_DIR, 'glove.6B.100d.txt'))\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))\n",
    "\n",
    "# second, prepare text samples and their labels\n",
    "print('Processing text dataset')\n",
    "\n",
    "texts = []  # list of text samples\n",
    "labels_index = {}  # dictionary mapping label name to numeric id\n",
    "labels = []  # list of label ids\n",
    "for name in sorted(os.listdir(TEXT_DATA_DIR)):\n",
    "    path = os.path.join(TEXT_DATA_DIR, name)\n",
    "    if os.path.isdir(path):\n",
    "        label_id = len(labels_index)\n",
    "        labels_index[name] = label_id\n",
    "        for fname in sorted(os.listdir(path)):\n",
    "            if fname.isdigit():\n",
    "                fpath = os.path.join(path, fname)\n",
    "                if sys.version_info < (3,):\n",
    "                    f = open(fpath)\n",
    "                else:\n",
    "                    f = open(fpath, encoding='latin-1')\n",
    "                t = f.read()\n",
    "                i = t.find('\\n\\n')  # skip header\n",
    "                if 0 < i:\n",
    "                    t = t[i:]\n",
    "                texts.append(t)\n",
    "                f.close()\n",
    "                labels.append(label_id)\n",
    "\n",
    "print('Found %s texts.' % len(texts))\n",
    "\n",
    "# finally, vectorize the text samples into a 2D integer tensor\n",
    "tokenizer = Tokenizer(num_words=MAX_NUM_WORDS)\n",
    "tokenizer.fit_on_texts(texts)\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))\n",
    "\n",
    "data = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "labels = to_categorical(np.asarray(labels))\n",
    "print('Shape of data tensor:', data.shape)\n",
    "print('Shape of label tensor:', labels.shape)\n",
    "\n",
    "# split the data into a training set and a validation set\n",
    "indices = np.arange(data.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "data = data[indices]\n",
    "labels = labels[indices]\n",
    "num_validation_samples = int(VALIDATION_SPLIT * data.shape[0])\n",
    "\n",
    "x_train = data[:-num_validation_samples]\n",
    "y_train = labels[:-num_validation_samples]\n",
    "x_val = data[-num_validation_samples:]\n",
    "y_val = labels[-num_validation_samples:]\n",
    "\n",
    "print('Preparing embedding matrix.')\n",
    "\n",
    "# prepare embedding matrix\n",
    "num_words = min(MAX_NUM_WORDS, len(word_index))\n",
    "embedding_matrix = np.zeros((num_words, EMBEDDING_DIM))\n",
    "for word, i in word_index.items():\n",
    "    if i >= MAX_NUM_WORDS:\n",
    "        continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "\n",
    "# load pre-trained word embeddings into an Embedding layer\n",
    "# note that we set trainable = False so as to keep the embeddings fixed\n",
    "embedding_layer = Embedding(num_words,\n",
    "                            EMBEDDING_DIM,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=MAX_SEQUENCE_LENGTH,\n",
    "                            trainable=False)\n",
    "\n",
    "print('Training model.')\n",
    "\n",
    "# train a 1D convnet with global maxpooling\n",
    "\n",
    "sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "embedded_sequences = embedding_layer(sequence_input)\n",
    "\n",
    "#Model 1\n",
    "l_cov1= Conv1D(128, 5, activation='relu')(embedded_sequences)\n",
    "l_pool1 = MaxPooling1D(5)(l_cov1)\n",
    "l_drop1= Dropout(0.2)(l_pool1)\n",
    "l_cov2 = Conv1D(128, 5, activation='relu')(l_drop1)\n",
    "l_pool2 = MaxPooling1D(5)(l_cov2)\n",
    "l_drop2 = Dropout(0.2)(l_pool2)\n",
    "l_cov3 = Conv1D(128, 5, activation='relu')(l_drop2)\n",
    "l_pool3 = MaxPooling1D(35)(l_cov3)  # global max pooling\n",
    "l_flat = Flatten()(l_pool3)\n",
    "l_dense = Dense(128, activation='relu')(l_flat)\n",
    "preds = Dense(len(labels_index), activation='softmax')(l_dense)\n",
    "\n",
    "optimizer = optimizers.RMSprop(lr=learning_rate, clipnorm = max_grad_norm)\n",
    "model = Model(sequence_input, preds)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['acc'])\n",
    "\n",
    "model_details = model.fit(x_train, y_train,\n",
    "            batch_size=128,\n",
    "            epochs=100,\n",
    "            validation_data=(x_val, y_val))\n",
    "\n",
    "scores = model.evaluate(x_val,y_val, verbose=0)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "embedded_sequences = embedding_layer(sequence_input)\n",
    "convs = []\n",
    "filter_sizes = [3,4,5]\n",
    "\n",
    "for fsz in filter_sizes:\n",
    "    l_conv = Conv1D(nb_filter=128,filter_length=fsz,activation='relu')(embedded_sequences)\n",
    "    l_pool = MaxPooling1D(5)(l_conv)\n",
    "    convs.append(l_pool)\n",
    "    \n",
    "l_merge = Merge(mode='concat', concat_axis=1)(convs)\n",
    "l_cov1= Conv1D(128, 5, activation='relu')(l_merge)\n",
    "l_pool1 = MaxPooling1D(5)(l_cov1)\n",
    "l_cov2 = Conv1D(128, 5, activation='relu')(l_pool1)\n",
    "l_pool2 = MaxPooling1D(30)(l_cov2)\n",
    "l_flat = Flatten()(l_pool2)\n",
    "l_dense = Dense(128, activation='relu')(l_flat)\n",
    "preds = Dense(len(labels_index), activation='softmax')(l_dense)\n",
    "\n",
    "model = Model(sequence_input, preds)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['acc'])\n",
    "\n",
    "print(\"model fitting - more complex convolutional neural network\")\n",
    "#model.summary()\n",
    "model.fit(x_train, y_train, validation_data=(x_val, y_val),\n",
    "          nb_epoch=10, batch_size=50)\n",
    "scores = model.evaluate(x_val,y_val, verbose=0)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQ_LENGTH = 64\n",
    "\n",
    "def build_bert_dataset(text,labels,dict_genre):\n",
    "\ttokenization.validate_case_matches_checkpoint(True,INIT_CHECKPOINT)\n",
    "\tbert_tokenizer = tokenization.FullTokenizer(vocab_file=VOCAB_FILE, do_lower_case=True)\n",
    "\tprint(\"BERT Vocab length = \",len(bert_tokenizer.vocab))\n",
    "    \n",
    "\tjoblib.dump(bert_tokenizer, \"bert_tokenizer.pickle\")\n",
    "\n",
    "\tx_train, x_test, y_train, y_test = train_test_split(text,labels,test_size=0.2)\n",
    "\n",
    "\ty_train_df = pd.DataFrame(y_train,columns = ['label'])\n",
    "\ty_test_df = pd.DataFrame(y_test,columns = ['label'])\n",
    "    \n",
    "\ty_train_num = y_train_df.label.apply(lambda x: dict_genre[x])\n",
    "\ty_test_num = y_test_df.label.apply(lambda x: dict_genre[x])   \n",
    "    \n",
    "\tx_train_df = pd.DataFrame(x_train,columns = ['text'])\n",
    "\tx_test_df = pd.DataFrame(x_test,columns = ['text'])\n",
    "    \n",
    "\ttrain_df = pd.concat([x_train_df.text,y_train_num],axis=1)\n",
    "\ttest_df = pd.concat([x_test_df.text, y_test_num],axis=1)\n",
    "\n",
    "\tDATA_COLUMN,LABEL_COLUMN = 0,1\n",
    "\n",
    "\t# Use the InputExample class from BERT's run_classifier code to create examples from the data\n",
    "\ttrain_InputExamples = train_df.apply(lambda x: bert.run_classifier.InputExample(guid=None, # Globally unique ID for bookkeeping, unused in this example\n",
    "                                                                   text_a = x.text, \n",
    "                                                                   text_b = None, \n",
    "                                                                   label = x.label), axis = 1)\n",
    "\n",
    "\ttest_InputExamples = test_df.apply(lambda x: bert.run_classifier.InputExample(guid=None, \n",
    "                                                                   text_a = x.text, \n",
    "                                                                   text_b = None, \n",
    "                                                                   label = x.label), axis = 1)\n",
    "    \n",
    "\tlabel_list = list(dict_genre.values())\n",
    "\t# We'll set sequences to be at most 128 tokens long.\n",
    "\t# Convert our train and test features to InputFeatures that BERT understands.\n",
    "\ttrain_features = bert.run_classifier.convert_examples_to_features(train_InputExamples, label_list, MAX_SEQ_LENGTH, bert_tokenizer)\n",
    "\ttest_features = bert.run_classifier.convert_examples_to_features(test_InputExamples, label_list, MAX_SEQ_LENGTH, bert_tokenizer)\n",
    "\treturn train_features, test_features  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing the data...\n",
      "Data processing done!!\n",
      "completed in : 34.89013409614563 seconds\n",
      "{'Rock': 1, 'Not Available': 6, 'Pop': 0, 'Jazz': 4, 'Hip-Hop': 2, 'Country': 3, 'Other': 5}\n"
     ]
    }
   ],
   "source": [
    "# BEFORE USING BERT METHOD\n",
    "# process the lyrics, convert into train and test\n",
    "start = time.time()\n",
    "text, labels, genre_dict = pre_process()\n",
    "end = time.time()\n",
    "print(\"completed in :\",end - start,\"seconds\")\n",
    "print(genre_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total text rows: 7000\n",
      "total label rows: 7000\n",
      "total genre rows: 7\n"
     ]
    }
   ],
   "source": [
    "print('total text rows:',len(text))\n",
    "print('total label rows:',len(labels))\n",
    "print('total genre rows:',len(genre_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT Vocab length =  30522\n",
      "completed in : 31.088528633117676 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "train_features, test_features = build_bert_dataset(text,labels,genre_dict)\n",
    "end = time.time()\n",
    "print(\"completed in :\",end - start,\"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(is_predicting, input_ids, input_mask, segment_ids, labels,\n",
    "                 num_labels):\n",
    "  \"\"\"Creates a classification model.\"\"\"\n",
    "\n",
    "  bert_module = hub.Module(\n",
    "      BERT_MODEL_HUB,\n",
    "      trainable=True)\n",
    "  bert_inputs = dict(\n",
    "      input_ids=input_ids,\n",
    "      input_mask=input_mask,\n",
    "      segment_ids=segment_ids)\n",
    "  bert_outputs = bert_module(\n",
    "      inputs=bert_inputs,\n",
    "      signature=\"tokens\",\n",
    "      as_dict=True)\n",
    "\n",
    "  # Use \"pooled_output\" for classification tasks on an entire sentence.\n",
    "  # Use \"sequence_outputs\" for token-level output.\n",
    "  output_layer = bert_outputs[\"pooled_output\"]\n",
    "\n",
    "  hidden_size = output_layer.shape[-1].value\n",
    "\n",
    "  # Create our own layer to tune for politeness data.\n",
    "  output_weights = tf.get_variable(\n",
    "      \"output_weights\", [num_labels, hidden_size],\n",
    "      initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "\n",
    "  output_bias = tf.get_variable(\n",
    "      \"output_bias\", [num_labels], initializer=tf.zeros_initializer())\n",
    "\n",
    "  with tf.variable_scope(\"loss\"):\n",
    "\n",
    "    # Dropout helps prevent overfitting\n",
    "    output_layer = tf.nn.dropout(output_layer, keep_prob=0.9)\n",
    "\n",
    "    logits = tf.matmul(output_layer, output_weights, transpose_b=True)\n",
    "    logits = tf.nn.bias_add(logits, output_bias)\n",
    "    log_probs = tf.nn.log_softmax(logits, axis=-1)\n",
    "\n",
    "    # Convert labels into one-hot encoding\n",
    "    one_hot_labels = tf.one_hot(labels, depth=num_labels, dtype=tf.float32)\n",
    "\n",
    "    predicted_labels = tf.squeeze(tf.argmax(log_probs, axis=-1, output_type=tf.int32))\n",
    "    # If we're predicting, we want predicted labels and the probabiltiies.\n",
    "    if is_predicting:\n",
    "      return (predicted_labels, log_probs)\n",
    "\n",
    "    # If we're train/eval, compute loss between predicted and actual label\n",
    "    per_example_loss = -tf.reduce_sum(one_hot_labels * log_probs, axis=-1)\n",
    "    loss = tf.reduce_mean(per_example_loss)\n",
    "    return (loss, predicted_labels, log_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_fn_builder actually creates our model function\n",
    "# using the passed parameters for num_labels, learning_rate, etc.\n",
    "def model_fn_builder(num_labels, learning_rate, num_train_steps,\n",
    "                     num_warmup_steps):\n",
    "  \"\"\"Returns `model_fn` closure for TPUEstimator.\"\"\"\n",
    "  def model_fn(features, labels, mode, params):  # pylint: disable=unused-argument\n",
    "    \"\"\"The `model_fn` for TPUEstimator.\"\"\"\n",
    "\n",
    "    input_ids = features[\"input_ids\"]\n",
    "    input_mask = features[\"input_mask\"]\n",
    "    segment_ids = features[\"segment_ids\"]\n",
    "    label_ids = features[\"label_ids\"]\n",
    "\n",
    "    is_predicting = (mode == tf.estimator.ModeKeys.PREDICT)\n",
    "    \n",
    "    # TRAIN and EVAL\n",
    "    if not is_predicting:\n",
    "\n",
    "      (loss, predicted_labels, log_probs) = create_model(\n",
    "        is_predicting, input_ids, input_mask, segment_ids, label_ids, num_labels)\n",
    "\n",
    "      train_op = bert.optimization.create_optimizer(\n",
    "          loss, learning_rate, num_train_steps, num_warmup_steps, use_tpu=False)\n",
    "\n",
    "      # Calculate evaluation metrics. \n",
    "      def metric_fn(label_ids, predicted_labels):\n",
    "        accuracy = tf.metrics.accuracy(label_ids, predicted_labels)\n",
    "        #f1_score = tf.contrib.metrics.f1_score(\n",
    "        #    label_ids,\n",
    "        #    predicted_labels)\n",
    "        #auc = tf.metrics.auc(\n",
    "        #    label_ids,\n",
    "        #    predicted_labels)\n",
    "        #recall = tf.metrics.recall(\n",
    "        #    label_ids,\n",
    "        #    predicted_labels)\n",
    "        #precision = tf.metrics.precision(\n",
    "        #    label_ids,\n",
    "        #    predicted_labels) \n",
    "        #true_pos = tf.metrics.true_positives(\n",
    "        #    label_ids,\n",
    "        #    predicted_labels)\n",
    "        #true_neg = tf.metrics.true_negatives(\n",
    "        #    label_ids,\n",
    "        #    predicted_labels)   \n",
    "        #false_pos = tf.metrics.false_positives(\n",
    "        #    label_ids,\n",
    "        #    predicted_labels)  \n",
    "        #false_neg = tf.metrics.false_negatives(\n",
    "        #    label_ids,\n",
    "        #    predicted_labels)\n",
    "        return {\n",
    "            \"eval_accuracy\": accuracy#,\n",
    "            #\"f1_score\": f1_score,\n",
    "            #\"auc\": auc,\n",
    "            #\"precision\": precision,\n",
    "            #\"recall\": recall,\n",
    "            #\"true_positives\": true_pos,\n",
    "            #\"true_negatives\": true_neg,\n",
    "            #\"false_positives\": false_pos,\n",
    "            #\"false_negatives\": false_neg\n",
    "        }\n",
    "\n",
    "      eval_metrics = metric_fn(label_ids, predicted_labels)\n",
    "\n",
    "      if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        return tf.estimator.EstimatorSpec(mode=mode,\n",
    "          loss=loss,\n",
    "          train_op=train_op)\n",
    "      else:\n",
    "          return tf.estimator.EstimatorSpec(mode=mode,\n",
    "            loss=loss,\n",
    "            eval_metric_ops=eval_metrics)\n",
    "    else:\n",
    "      (predicted_labels, log_probs) = create_model(\n",
    "        is_predicting, input_ids, input_mask, segment_ids, label_ids, num_labels)\n",
    "\n",
    "      predictions = {\n",
    "          'probabilities': log_probs,\n",
    "          'labels': predicted_labels\n",
    "      }\n",
    "      return tf.estimator.EstimatorSpec(mode, predictions=predictions)\n",
    "\n",
    "  # Return the actual model function in the closure\n",
    "  return model_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute train and warmup steps from batch size\n",
    "# These hyperparameters are copied from this colab notebook (https://colab.sandbox.google.com/github/tensorflow/tpu/blob/master/tools/colab/bert_finetuning_with_cloud_tpus.ipynb)\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 2e-5\n",
    "NUM_TRAIN_EPOCHS = 3.0\n",
    "# Warmup is a period of time where hte learning rate \n",
    "# is small and gradually increases--usually helps training.\n",
    "WARMUP_PROPORTION = 0.1\n",
    "# Model configs\n",
    "SAVE_CHECKPOINTS_STEPS = 500\n",
    "SAVE_SUMMARY_STEPS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute # train and warmup steps from batch size\n",
    "num_train_steps = int(len(train_features) / BATCH_SIZE * NUM_TRAIN_EPOCHS)\n",
    "num_warmup_steps = int(num_train_steps * WARMUP_PROPORTION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify output directory and number of checkpoint steps to save\n",
    "run_config = tf.estimator.RunConfig(\n",
    "    model_dir=\".\",\n",
    "    save_summary_steps=SAVE_SUMMARY_STEPS,\n",
    "    save_checkpoints_steps=SAVE_CHECKPOINTS_STEPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fn = model_fn_builder(\n",
    "  num_labels=len(list(genre_dict.values())),\n",
    "  learning_rate=LEARNING_RATE,\n",
    "  num_train_steps=num_train_steps,\n",
    "  num_warmup_steps=num_warmup_steps)\n",
    "\n",
    "estimator = tf.estimator.Estimator(\n",
    "  model_fn=model_fn,\n",
    "  config=run_config,\n",
    "  params={\"batch_size\": BATCH_SIZE})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an input function for training. drop_remainder = True for using TPUs.\n",
    "train_input_fn = bert.run_classifier.input_fn_builder(\n",
    "    features=train_features,\n",
    "    seq_length=MAX_SEQ_LENGTH,\n",
    "    is_training=True,\n",
    "    drop_remainder=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning Training!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/schakraverty/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/home/schakraverty/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "W0729 00:36:48.459028 140054812354304 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 50 vs previous value: 50. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
      "W0729 00:37:25.723884 140054812354304 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 59 vs previous value: 59. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
      "W0729 00:39:17.613873 140054812354304 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 87 vs previous value: 87. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
      "W0729 00:39:52.658988 140054812354304 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 96 vs previous value: 96. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training took time  0:36:36.201119\n"
     ]
    }
   ],
   "source": [
    "BERT_MODEL_HUB = \"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\"\n",
    "print('Beginning Training!')\n",
    "current_time = datetime.now()\n",
    "estimator.train(input_fn=train_input_fn, max_steps=num_train_steps)\n",
    "print(\"Training took time \", datetime.now() - current_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input_fn = run_classifier.input_fn_builder(\n",
    "    features=test_features,\n",
    "    seq_length=MAX_SEQ_LENGTH,\n",
    "    is_training=False,\n",
    "    drop_remainder=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/schakraverty/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/home/schakraverty/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_accuracy': 0.47642857, 'global_step': 525, 'loss': 1.5308177}"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.evaluate(input_fn=test_input_fn, steps=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@article{devlin2018bert,\n",
    "  title={BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},\n",
    "  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},\n",
    "  journal={arXiv preprint arXiv:1810.04805},\n",
    "  year={2018}\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Application of New Concepts\n",
    "\n",
    "\n",
    "Throughout the project we sought to implement a scalable solution with consideration to the problem context.  BERT’s key technical innovation is applying the bidirectional training of Transformer, a popular attention model, to language modelling. This is in contrast to previous efforts which looked at a text sequence either from left to right or combined left-to-right and right-to-left training. The BERT paper’s results show that a language model which is bidirectionally trained can have a deeper sense of language context and flow than single-direction language models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. References\n",
    "\n",
    "__[FULL LIST WILL BE UPDATED AS WE COMPLETE PROJECT]__\n",
    "\n",
    "(1) [The State of Streaming Music Services](https://www.pcmag.com/roundup/260966/the-best-online-music-streaming-services)\n",
    "\n",
    "(2) [Spotify - For the record](https://newsroom.spotify.com/company-info/)\n",
    "\n",
    "(3) [Understanding AUC ROC](https://towardsdatascience.com/understanding-auc-roc-curve-68b2303cc9c5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "441px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": true,
   "toc_position": {
    "height": "827px",
    "left": "0px",
    "right": "1125px",
    "top": "107px",
    "width": "428px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
